{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing the libraries and the dataset\n",
    "import numpy as np\n",
    "from keras.datasets import imdb\n",
    "import matplotlib.pyplot as plt\n",
    "# load the dataset\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data()\n",
    "X = np.concatenate((X_train, X_test), axis=0)\n",
    "y = np.concatenate((y_train, y_test), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'boiled', 'full', 'involving', 'to', 'impressive', 'boring', 'this', 'as', 'murdering', 'naschy', 'br', 'villain', 'council', 'suggestion', 'need', 'has', 'of', 'costumes', 'b', 'message', 'to', 'may', 'of', 'props', 'this', 'echoed', 'concentrates', 'concept', 'issue', 'skeptical', 'to', \"god's\", 'he', 'is', 'dedications', 'unfolds', 'movie', 'women', 'like', \"isn't\", 'surely', \"i'm\", 'rocketed', 'to', 'toward', 'in', \"here's\", 'for', 'from', 'did', 'having', 'because', 'very', 'quality', 'it', 'is', \"captain's\", 'starship', 'really', 'book', 'is', 'both', 'too', 'worked', 'carl', 'of', 'mayfair', 'br', 'of', 'reviewer', 'closer', 'figure', 'really', 'there', 'will', 'originals', 'things', 'is', 'far', 'this', 'make', 'mistakes', \"kevin's\", 'was', \"couldn't\", 'of', 'few', 'br', 'of', 'you', 'to', \"don't\", 'female', 'than', 'place', 'she', 'to', 'was', 'between', 'that', 'nothing', 'dose', 'movies', 'get', 'are', '498', 'br', 'yes', 'female', 'just', 'its', 'because', 'many', 'br', 'of', 'overly', 'to', 'descent', 'people', 'time', 'very', 'bland']\n",
      "1\n",
      "[1, 6740, 365, 1234, 5, 1156, 354, 11, 14, 5327, 6638, 7, 1016, 10626, 5940, 356, 44, 4, 1349, 500, 746, 5, 200, 4, 4132, 11, 16393, 9363, 1117, 1831, 7485, 5, 4831, 26, 6, 71690, 4183, 17, 369, 37, 215, 1345, 143, 32677, 5, 1838, 8, 1974, 15, 36, 119, 257, 85, 52, 486, 9, 6, 26441, 8564, 63, 271, 6, 196, 96, 949, 4121, 4, 74170, 7, 4, 2212, 2436, 819, 63, 47, 77, 7175, 180, 6, 227, 11, 94, 2494, 33740, 13, 423, 4, 168, 7, 4, 22, 5, 89, 665, 71, 270, 56, 5, 13, 197, 12, 161, 5390, 99, 76, 23, 77842, 7, 419, 665, 40, 91, 85, 108, 7, 4, 2084, 5, 4773, 81, 55, 52, 1901]\n"
     ]
    }
   ],
   "source": [
    "# Getting the words actually written in the review\n",
    "word2id = imdb.get_word_index()\n",
    "id2word = {i: word for word, i in word2id.items()}\n",
    "print([id2word.get(i, ' ') for i in X_train[6]])\n",
    "print(y_train[6])\n",
    "print(X_train[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: \n",
      "(50000,)\n",
      "(50000,)\n"
     ]
    }
   ],
   "source": [
    "# summarize the dataset size\n",
    "\n",
    "'''\n",
    "From this snippet we can see that there are 50000 movie reviews in total. 25000 in the training and testing sets, respectively.\n",
    "'''\n",
    "\n",
    "print(\"Training data: \")\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: \n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "# Summarize number of classes\n",
    "\n",
    "'''\n",
    "There are only two unique sentiments: positive (1) and negative (0).\n",
    "'''\n",
    "\n",
    "print(\"Classes: \")\n",
    "print(np.unique(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words: \n",
      "88585\n"
     ]
    }
   ],
   "source": [
    "# Summarize number of unique words\n",
    "\n",
    "'''\n",
    "There are almost 90 000 unique words in the combined dataset, i.e. all 50 000 reviews.\n",
    "\n",
    "This is interesting. We have about 1.8 unique words per review, which is a small number. This just goes to show how much we\n",
    "reuse words in a single sentence/review. \n",
    "\n",
    "This could also be an indication that most people's vocabularies are similar. Across 50000 reviews we only use roughly 90000 different words.\n",
    "'''\n",
    "\n",
    "print(\"Number of unique words: \")\n",
    "print(len(np.unique(np.hstack(X))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review length: \n",
      "Mean 234.76 words (172.911495)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minimum review length is 7.\n",
      "The maximum review length is 2494.\n"
     ]
    }
   ],
   "source": [
    "# Summarize review length\n",
    "\n",
    "'''\n",
    "Below is a summary of the review length. We can see that an average review is about 230 words long. The maximum review \n",
    "length is just below 2500 words, with the shortest review being only 7 words.\n",
    "'''\n",
    "\n",
    "print(\"Review length: \")\n",
    "result = [len(x) for x in X]\n",
    "print(\"Mean %.2f words (%f)\" % (np.mean(result), np.std(result)))\n",
    "\n",
    "# plot review length\n",
    "ax, fig = plt.subplots(figsize = (10, 8))\n",
    "plt.boxplot(result)\n",
    "plt.title(\"Review lenghts\")\n",
    "plt.ylabel(\"Number of words\")\n",
    "plt.show()\n",
    "\n",
    "# Min and max review lengths\n",
    "print(f\"The minimum review length is {min(result)}.\")\n",
    "print(f\"The maximum review length is {max(result)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this RNN we will be making use of a word embedding representation for the IMDB dataset. This requires the use of an embedding layer. Keras offers this embedding layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required modeling libraries for the Recurrent Neural Network (RNN)\n",
    "import numpy\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset but only keep the top n words, zero the rest. We set the 'vocabulary size' to 5000 words\n",
    "top_words = 5000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)\n",
    "\n",
    "# We cap the number of words per review\n",
    "'''\n",
    "pad_sequences is used to ensure that all sequences in a list have the same length. \n",
    "By default this is done by padding 0 in the beginning of each sequence until each sequence has the same length as the \n",
    "longest sequence. We will bound reviews at 500 words, truncating longer reviews and zero-padding shorter reviews.\n",
    "\n",
    "We will also use a 50/50 split of the dataset into training and test.\n",
    "'''\n",
    "max_words = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 500, 32)           160000    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 250)               4000250   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 251       \n",
      "=================================================================\n",
      "Total params: 4,160,501\n",
      "Trainable params: 4,160,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "We will use an Embedding layer as the input layer, setting the vocabulary to 5000. \n",
    "The word vector size is set to 32 dimensions and the input_length to 500. \n",
    "The output of this first layer will be a 32×500 sized matrix.\n",
    "'''\n",
    "# Creating the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, 32, input_length=max_words)) # Embedding layer\n",
    "model.add(Flatten()) # Flatten the Embedded layers output to one dimension\n",
    "model.add(Dense(250, activation='relu')) # Dense hidden layer with a relu activation function\n",
    "model.add(Dense(1, activation='sigmoid')) # Output layer (one neuron) with a sigmoid activation to output values of 0 and 1 as predictions\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) # Logarithmic loss in used\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      " - 16s - loss: 0.5093 - acc: 0.7117 - val_loss: 0.3148 - val_acc: 0.8632\n",
      "Epoch 2/2\n",
      " - 15s - loss: 0.1899 - acc: 0.9274 - val_loss: 0.3011 - val_acc: 0.8723\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nWe only use 2 epochs. The reason for this is to prevent overfitting - such RNN's have been known to overfit quickly.\\n\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "'''\n",
    "We only use 2 epochs. The reason for this is to prevent overfitting - such RNN's have been known to overfit quickly.\n",
    "There is a lot of data so we will use a batch size of 128.\n",
    "'''\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=2, batch_size=128, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.23%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model on the test set. This is where we predict the movie sentiments on an unseen set of reviews.\n",
    "'''\n",
    "The evaluation of the model on the test set is also shown in the above cell. The model.fit instruction performs the validation\n",
    "on the test set as well.\n",
    "'''\n",
    "\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of initial results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We confirm in the above cell that the accuracy on the test set of 25000 reviews is just over 87%. This is very good! This means that we correctly predicted roughly 22000 of the 25000 (unseen) movie review sentiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model refinement\n",
    "\n",
    "We were able to achieve a high model accuracy with little effort. Could we improve this accuracy even further? In the section below we try to do so. Two suggested ways of doing so are:\n",
    "\n",
    " - Using a larger embedding\n",
    " - Adding more hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 500, 64)           320000    \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 32000)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 250)               8000250   \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 251       \n",
      "=================================================================\n",
      "Total params: 8,320,501\n",
      "Trainable params: 8,320,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Embedded layer size: 64 None\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      " - 31s - loss: 0.5225 - acc: 0.7053 - val_loss: 0.3041 - val_acc: 0.8703\n",
      "Epoch 2/2\n",
      " - 31s - loss: 0.1895 - acc: 0.9278 - val_loss: 0.3145 - val_acc: 0.8714\n",
      " \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 500, 128)          640000    \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 64000)             0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 250)               16000250  \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 251       \n",
      "=================================================================\n",
      "Total params: 16,640,501\n",
      "Trainable params: 16,640,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Embedded layer size: 128 None\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      " - 65s - loss: 0.5472 - acc: 0.6882 - val_loss: 0.3221 - val_acc: 0.8629\n",
      "Epoch 2/2\n",
      " - 65s - loss: 0.1897 - acc: 0.9276 - val_loss: 0.3115 - val_acc: 0.8735\n",
      " \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 500, 256)          1280000   \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 128000)            0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 250)               32000250  \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 251       \n",
      "=================================================================\n",
      "Total params: 33,280,501\n",
      "Trainable params: 33,280,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Embedded layer size: 256 None\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      " - 135s - loss: 0.6361 - acc: 0.6306 - val_loss: 0.3388 - val_acc: 0.8512\n",
      "Epoch 2/2\n",
      " - 130s - loss: 0.2198 - acc: 0.9128 - val_loss: 0.3043 - val_acc: 0.8709\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Larger embedding\n",
    "\n",
    "'''\n",
    "We keep using 2 epochs and a batch size of 128. We only increase the size of the embedded layer's output.\n",
    "'''\n",
    "\n",
    "embedded_size = [64, 128, 256]\n",
    "\n",
    "for size in embedded_size:\n",
    "    # Creating the model\n",
    "    model_2 = Sequential()\n",
    "    model_2.add(Embedding(top_words, size, input_length=max_words)) # Embedding layer\n",
    "    model_2.add(Flatten()) # Flatten the Embedded layers output to one dimension\n",
    "    model_2.add(Dense(250, activation='relu')) # Dense hidden layer with a relu activation function\n",
    "    model_2.add(Dense(1, activation='sigmoid')) # Output layer (one neuron) with a sigmoid activation to output values of 0 and 1 as predictions\n",
    "    model_2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) # Logarithmic loss in used\n",
    "    print(f\"Embedded layer size: {size}\")\n",
    "    print(model_2.summary())\n",
    "\n",
    "    # Training the model\n",
    "    model_2.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=2, batch_size=128, verbose=2)\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above output we observe that as the embedded layer's size increases from 64 to 128 the model accuracy (on the second epoch) increases from 87.14% to 87.35%. The model performs best when this value is set to 128. The model does second best when this value is set to 32. There is therefore no clear linear relationship between the size of the embedding layer output and the model accuracy. For this exercise we conclude that using the embedding layer output dimension of 128 is most suitable. This may not always be the case - different problems will warrant different values for this parameter.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dense layers = 1\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_15 (Embedding)     (None, 500, 256)          1280000   \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 128000)            0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 250)               32000250  \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 1)                 251       \n",
      "=================================================================\n",
      "Total params: 33,280,501\n",
      "Trainable params: 33,280,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      " \n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      " - 133s - loss: 0.5124 - acc: 0.7479 - val_loss: 0.2902 - val_acc: 0.8778\n",
      "Epoch 2/2\n",
      " - 138s - loss: 0.1351 - acc: 0.9513 - val_loss: 0.3321 - val_acc: 0.8659\n",
      "Number of dense layers = 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_16 (Embedding)     (None, 500, 256)          1280000   \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 128000)            0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 250)               32000250  \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 250)               62750     \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 1)                 251       \n",
      "=================================================================\n",
      "Total params: 33,343,251\n",
      "Trainable params: 33,343,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      " \n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      " - 136s - loss: 0.4736 - acc: 0.7530 - val_loss: 0.2895 - val_acc: 0.8772\n",
      "Epoch 2/2\n",
      " - 131s - loss: 0.1332 - acc: 0.9510 - val_loss: 0.3690 - val_acc: 0.8612\n",
      "Number of dense layers = 3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_17 (Embedding)     (None, 500, 256)          1280000   \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 128000)            0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 250)               32000250  \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 250)               62750     \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 250)               62750     \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 1)                 251       \n",
      "=================================================================\n",
      "Total params: 33,406,001\n",
      "Trainable params: 33,406,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      " \n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      " - 142s - loss: 0.4416 - acc: 0.7700 - val_loss: 0.2905 - val_acc: 0.8766\n",
      "Epoch 2/2\n",
      " - 144s - loss: 0.1089 - acc: 0.9618 - val_loss: 0.4003 - val_acc: 0.8500\n"
     ]
    }
   ],
   "source": [
    "# Added hidden layers\n",
    "\n",
    "# Range of hidden dense layers that will be tested\n",
    "num_of_hidden_layers = [1, 2, 3]\n",
    "\n",
    "for num in num_of_hidden_layers:\n",
    "    model_3 = Sequential()\n",
    "    model_3.add(Embedding(top_words, 128, input_length=max_words)) # Embedding layer\n",
    "    model_3.add(Flatten()) # Flatten the Embedded layers output to one dimension\n",
    "    # Adding the required number of hidden dense layers\n",
    "    for i in range(num):\n",
    "        model_3.add(Dense(250, activation='relu')) # Dense hidden layer with a relu activation function\n",
    "    model_3.add(Dense(1, activation='sigmoid')) # Output layer (one neuron) with a sigmoid activation to output values of 0 and 1 as predictions\n",
    "    model_3.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) # Logarithmic loss in used\n",
    "    print(f\"Number of dense layers = {num}\")\n",
    "    print(model_3.summary())\n",
    "      \n",
    "    # Training the model\n",
    "    model_3.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=2, batch_size=128, verbose=2)\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two observations that we can derive from the above output:\n",
    "\n",
    " - The first is that we notice how increasing the number of hidden dense layers does not necessarily lead to an improved model. In fact, on the above dataset we see that the model's accuracy actually decreases as we increase the number of hidden dense layers from 1 to 2 to 3. In addition to decreasing the model accuracy, adding more hidden dense layers also leads to longer runtimes for the models. It does therefore not make sense to have more than 1 hidden dense layer (of size 250) for this particular problem.\n",
    " \n",
    " - The second observation is that the model accuracy on the first epoch is higher than the accuracy on the second epoch. The model's accuracy on the training set improves if we run two epochs, but it reduces on the test set. This is likely an indication of overfitting. This overfitting effect becomes more pronounced as the total number of layers increases.\n",
    " \n",
    "Recommendation - The model structure set out below produced the most accurate results for this problem: \n",
    "\n",
    " - Layers of the model = One embedded layer, one hidden dense layer (size 250, relu activation), one output layer (sigmoid activation) \n",
    " - Embedded layer size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Something\n",
    "\n",
    "We will use the below movie reviews and use our model to predict whether it is positive or negative. From reading the reviews I would label them as follows:\n",
    "\n",
    "Review 1 = Negative (0);\n",
    "Review 2 = Positive (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review 1: \n",
    "\n",
    "\"Terrible acting!! Too many changes from original. They took out too many important parts of the original. Showing the strength of Mufasa but also his friendly side (his friendship with Zazu, how he respects and hugs Rafiki, that he taught Simba how to pounce). Even the opening scene wasn’t the same. Why would you alter that? The huge rising sun in tune with the music that gives almost everyone goosebumps. The new one you see trees with a slightly lit up morning sky and then a small sun appears off to the side that isn’t in sync with the music. Mufasas personality doesn’t sound the same even though it’s still James Earl Jones’ voice. It’s different somehow. The hyenas are not the same. They don’t make jokes and laugh at themselves like “make mine a cub sandwich” then laugh hysterically at their own jokes. They eliminated Ed, the one who doesn’t speak, just laughs. Timon isn’t flamboyant or half as funny as the original. The hula scene in the original was fast paced and funny to distract the hyenas. The new one he slowly sings “Be our Guest”?? No action and not as fun. In fact, ALL of the new characters (including Beyoncé) sound like they are just reading from a script and it’s really mundane and forced. None of them are in character and flow like the original. There’s no sass or wit. The music is boring. It’s a huge disappointment. Rafiki catches Simbas hair and knows immediately it’s him. In the original, he knows the scent, but it takes him a minute to figure it out and when he does, he’s ecstatic. Not in the remake. There is no image of Mufasa in the clouds to guide Simba to remember who he is. Rafiki doesn’t give him a lesson about how the past can hurt with his stick. Simba doesn’t hug Rafiki like his father did which is also symbolic to how Simba is like his father. I don’t understand why Disney would eliminate these bonds and characters that we all love and change it to make what is a visually stunning movie into something I will never want to see again.\"\n",
    "\n",
    "\n",
    "Review 2: \n",
    "\n",
    "To an unabashed degree, Hobbs & Shaw is a movie about wheelhouse capitalization – both in front of and behind the camera. Nobody here is exactly breaking new ground, but everyone is doing what they do best, and it’s really the film’s greatest strength. It’s always fun when you can feel a palpable confidence from a blockbuster, and this one has it flowing. Not every stylistic choice fully works (especially those that get significant set ups without big payoffs), and logic isn’t consistently the narrative’s greatest concern, but the majority of its big swings connect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reviews to predict\n",
    "predict_this_1 = \"Terrible acting!! Too many changes from original. They took out too many important parts of the original. Showing the strength of Mufasa but also his friendly side (his friendship with Zazu, how he respects and hugs Rafiki, that he taught Simba how to pounce). Even the opening scene wasn’t the same. Why would you alter that? The huge rising sun in tune with the music that gives almost everyone goosebumps. The new one you see trees with a slightly lit up morning sky and then a small sun appears off to the side that isn’t in sync with the music. Mufasas personality doesn’t sound the same even though it’s still James Earl Jones’ voice. It’s different somehow. The hyenas are not the same. They don’t make jokes and laugh at themselves like “make mine a cub sandwich” then laugh hysterically at their own jokes. They eliminated Ed, the one who doesn’t speak, just laughs. Timon isn’t flamboyant or half as funny as the original. The hula scene in the original was fast paced and funny to distract the hyenas. The new one he slowly sings “Be our Guest”?? No action and not as fun. In fact, ALL of the new characters (including Beyoncé) sound like they are just reading from a script and it’s really mundane and forced. None of them are in character and flow like the original. There’s no sass or wit. The music is boring. It’s a huge disappointment. Rafiki catches Simbas hair and knows immediately it’s him. In the original, he knows the scent, but it takes him a minute to figure it out and when he does, he’s ecstatic. Not in the remake. There is no image of Mufasa in the clouds to guide Simba to remember who he is. Rafiki doesn’t give him a lesson about how the past can hurt with his stick. Simba doesn’t hug Rafiki like his father did which is also symbolic to how Simba is like his father. I don’t understand why Disney would eliminate these bonds and characters that we all love and change it to make what is a visually stunning movie into something I will never want to see again.\"\n",
    "predict_this_2 = \"To an unabashed degree, Hobbs & Shaw is a movie about wheelhouse capitalization – both in front of and behind the camera. Nobody here is exactly breaking new ground, but everyone is doing what they do best, and it’s really the film’s greatest strength. It’s always fun when you can feel a palpable confidence from a blockbuster, and this one has it flowing. Not every stylistic choice fully works (especially those that get significant set ups without big payoffs), and logic isn’t consistently the narrative’s greatest concern, but the majority of its big swings connect.\"\n",
    "\n",
    "# Removing punctuation from the reviews\n",
    "import string\n",
    "predict_this_1 = predict_this_1.translate(str.maketrans('', '', string.punctuation))\n",
    "predict_this_2 = predict_this_2.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "# Splitting the new strings (without punctuation) into lists of individual words\n",
    "words_1 = predict_this_1.split()\n",
    "words_2 = predict_this_2.split()\n",
    "\n",
    "# Creating lists containing the IMDB index values for the words in each of the new reviews. \n",
    "# We also only consider words in the top 5000 as was done for the earlier models.\n",
    "x_test_1 = []\n",
    "for w in words_1:\n",
    "    if w in word2id and word2id[w]<=5000:\n",
    "        x_test_1.append(word2id[w])\n",
    "\n",
    "x_test_2 = []\n",
    "for w in words_2:\n",
    "    if w in word2id and word2id[w]<=5000:\n",
    "        x_test_2.append(word2id[w])\n",
    "\n",
    "# Creating a single array with both of the reviews' lists. Each entry in the array represents the indexed values for a single review\n",
    "x_test = np.array([x_test_1, x_test_2])\n",
    "\n",
    "# Padding each of the reviews to a size of 500\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=max_words) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 500, 128)          640000    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 64000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 250)               16000250  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 251       \n",
      "=================================================================\n",
      "Total params: 16,640,501\n",
      "Trainable params: 16,640,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      " - 65s - loss: 0.5057 - acc: 0.7402 - val_loss: 0.3054 - val_acc: 0.8690\n",
      "Epoch 2/2\n",
      " - 66s - loss: 0.1686 - acc: 0.9368 - val_loss: 0.3016 - val_acc: 0.8736\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb28050b00>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating and training the final model that will be used to predict the new review\n",
    "# Notice that we use the above recommended model with an embedded layer size of 128 and only one hidden dense layer\n",
    "\n",
    "model_final = Sequential()\n",
    "model_final.add(Embedding(top_words, 128, input_length=max_words)) # Embedding layer\n",
    "model_final.add(Flatten()) # Flatten the Embedded layers output to one dimension\n",
    "model_final.add(Dense(250, activation='relu')) # Dense hidden layer with a relu activation function\n",
    "model_final.add(Dense(1, activation='sigmoid')) # Output layer (one neuron) with a sigmoid activation to output values of 0 and 1 as predictions\n",
    "model_final.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) # Logarithmic loss in used\n",
    "print(model_final.summary())\n",
    "\n",
    "# Training the model\n",
    "model_final.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=2, batch_size=128, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0]], dtype=int32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the sentiments of each of the two movie reviews\n",
    "model_final.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above output we can see that both reviews are predicted to be 'Negative' by the last model we built. This can be seen by the 0's in the output array above.\n",
    "\n",
    "This result is what I expected for the first review. I am however surprised to see that the second review is labelled as 'Negative' as well. This might simply be a matter of personal opinion. Others might also feel that review 2 is not entirely 'Positive'. It could also be simply because that's the way the model was trained, i.e. similar types of reviews in the IMDB dataset (on which the model was trained) were labelled as 'Negative', which would cause the model to see similar reviews as 'Negative'. \n",
    "\n",
    "It's therefore difficult to say whether or not the model is correct in the case of review 2. We would however be confident in saying that the model correctly predicted review 1's sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
